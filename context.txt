# Context and motivation

Here are a few ways to think about the Collatz map. 

Every iteration of Collatz performs a shift-left in ternary (preserving information), and a "normalizing" step that shifts right in binary, to remove k zeroes. In between them, it adds a single tiny bit to cause the avalanche that changes state. The process can be pictured as moving back and forth between the two bases, shedding k every time but preserving the state of its overall evolution.

Between odd-to-odd steps, the lowest bit of n is set (because it's odd). The highest one bit must also exist _somewhere_, so both MSB and LSB can be considered delimiters without informational value. The interior "payload", interpreted as a string (one and zero being equally significant, and protected by the MSB by virtue of existing), is preserved by the binary shift-right operation (by the LSB) and represents the actual state of the process. It can be considered as a symbolic progression that's isomorphic to the arithmetic.

Minsky's two-tag string rewriting rule to reproduce the Collatz map (a->bc, b->a, c->aaa) is (I believe) cleverly obfuscated binary arithmetic, unrolled bit-by-bit, in the most painfully long-winded way possible, but also isomorphic in the end to the binary avalanche.

Those are mechanical transforms, let's step up a level of abstraction.

The /2 step of Collatz preserves the set of prime factors above 3, making that specific information chaos-invariant. The same is true of 3n. The +1 step then breaks multiplicative alignment, and rolls the prime factors over into a different but very constrained set (consecutive numbers share no prime factors). +1 doesn't destroy the factor set, it flips it: the complexity goes nowhere. This is another information channel, _also_ one odd-prime-list wide.

There is therefore an unbroken (and strongly-typed) path through all steps of the Collatz process. It is performing something like (?) a permutation of odd prime factor sets. +1 keeps jumping that factor set (permuting the permutation), but eventually has full coverage modulo any product of small primes. 

Because what's evolving is the prime factor set here, the actual value of n is a projection and its magnitude at any time has little meaning. In software terms, n acts like a pointer to the richer state information found in n's local neighborhood. Collatz is an algorithm running in _that_ domain, but projected onto the number line, with [very unfortunate] chaotic-looking behavior.

Generalizing again and ignoring n, the fingerprints themselves (pairs of neighbor odd core vectors) evolve like a finite state automaton (modulo the product of a given set of odd primes etc etc). The CRT prevents repetition by accumulating and propagating arithmetic misalignment moving forward (rather, it makes sure a given n doesn't appear again before cycling the product of small prime factors). In the negative, it might be pictured as a sieve of overlaid lattices of prime factor products.

After misaligning with all numbers with odd prime factors in a cycle, only powers of two could remain. Whether n could escape them with 1.5x scaling, and find new prime factors quickly enough to keep lengthening the cycle, would then be the question (the answer appears to be no, but it doesn't matter quite yet).

I offer the observation that all these things:

- binary avalanche
- symbolic progression
- two-tag string rewriting rule
- finite state automaton over neighboring odd-core fingerprints
- projection/indirection of the state of a complex internal process
- odd prime product lattice sieve
- cycling permutation of permutations of prime factor sets
- accumulation of modular constraints through systematic multiplicative mis-alignment

...may be the _same_ thing, which could explain some of the patterns seen in this data, or provide a set of lenses through which to view it.


(But a random thought for the margin: I think shedding k on every step is discarding far too much information... I'd guess a good fraction of a bit each iteration, often more. That's not sustainable, the orbit should collapse. In my mind this indicates we're picking up roughly as much new information as k discards on every step. I further suspect this couldn't be a long term thing, there being no way to "pay it back", and therefore every iteration must (somehow) gain raw congruence/constraint/state information proportional to either k or the previous value of k. What form that could take I have no idea. Pure speculation, but please note any suspiciously k-or-log-k-information-sized correlations in the per-step evolution).

